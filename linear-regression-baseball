

#Original Link: http://sujitpal.blogspot.com.br/2015/03/moneyball-predictions-using-linear.html


#Import packages
from __future__ import division
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

#Import dataset
baseball = pd.read_csv("/Users/flavioclesio/Documents/Github/learning-space/baseball.csv")

#Get dataframe only using data before 2002
moneyball = baseball[baseball["Year"] < 2002]

#Get the name of all teams
team_idx = {v:k for (k, v) in enumerate(moneyball["Team"].unique())}

#Built a teamID for each team in idx
moneyball["_TeamID"] = [team_idx[x] for x in moneyball["Team"]]

#Get data only the teams that went to playoffs
moneyball_playoff = moneyball[moneyball["Playoffs"]==1]

#Get data only the teams that wont come to playoffs
moneyball_nonplayoff = moneyball[moneyball["Playoffs"]==0]

#Scatter the teams in playoffs in red and black the teams that wont come to playoffs
plt.scatter(moneyball_playoff["W"], moneyball_playoff["_TeamID"], color="r")
plt.scatter(moneyball_nonplayoff["W"], moneyball_nonplayoff["_TeamID"], color="k")

#The original estimates of Paul Pasacota (95) that line that determines if the teams will go to playoffs or not
plt.vlines(95, 0, len(team_idx), colors="b", linestyles="solid")
plt.yticks([])

#Label at the scatter
plt.title ("Playoffs break line using Teams \n in comparison with Runs using a Paul DePodesta \n estimation of 95 wins")

#Put labels at the axis
plt.ylabel("Teams")
plt.xlabel("Runs")


#For the linear regression, we will use two variables in the dataset called RS = Runs Scored and RA = Runs Allowed
#The difference will be the main result of winner or loser team
moneyball["_RDiff"] = moneyball["RS"] - moneyball["RA"]
plt.scatter(moneyball["_RDiff"], moneyball["W"])
plt.xlabel("Run Difference")
plt.ylabel("Wins")
plt.title ("Run difference using Wins as main variable")

#We will use linear regression funcion in scikit
win_model = LinearRegression()

#The function fit will get the x values as trainning values, and y as target values
win_model.fit(np.matrix(moneyball["_RDiff"]).T, moneyball["W"])

#xs will be the min and max of the RDiff values
xs = [np.min(moneyball["_RDiff"]), np.max(moneyball["_RDiff"])]

#ys will be the predicton, using the predict() function 
ys = [win_model.predict(x) for x in xs]

#Plot the results
plt.plot(xs, ys, color = 'r', linewidth=2.5)

#Remove from the estimate the intercept and get the coeficients using the coef_ function
run_diff_to_win = (95 - win_model.intercept_) / win_model.coef_[0]

plt.grid(True)

print("Run difference between champs and losers: %.2f" % (run_diff_to_win))






#To predict Runs Allowed (RA) will be used three indicators called OBP (On Base Percentage), SLG (Slugging Percentage) and BA (Batting Average)  

#An array with Runs Scored values
y = np.array(moneyball["RS"])

#An array in vertical way using vstack function, some kind of concatenation
X = np.vstack((np.array(moneyball["OBP"]),     #OBP (On Base Percentage) values 
               np.array(moneyball["SLG"]),     #SLG (Slugging Percentage) values
               np.array(moneyball["BA"]))).T   #BA (Batting Average) values   

#Calls the linear regression function
rs_model = LinearRegression()

#Fit the model using at the x (independent variables) values OBP, SLG and BA; and the y is RS (dependent variable)
rs_model.fit(X, y)

#Print the coeficient of determination. See more in https://en.wikipedia.org/wiki/Coefficient_of_determination
print("R-squared[RS_1]: %.4f" % (rs_model.score(X, y)))

#R2: 0.9302

#Print the intercept and the coeficients 
print(rs_model.intercept_, rs_model.coef_)

# (Intercept): 788.457047081 [ OBP: 2917.42140821  SLG: 1637.92766577  BA: -368.96606009]

#The batting average is negative, and this is counterintuitive, 'cause the batting is the main objective of the game. 
#The explanation of the site says: "This is clearly non-intuitive and comes about because of multi-collinearity (ie multiple variables that vary in the same direction)."

#To remove this effect, we'll remove BA of the preditors (independent variable)
X = np.vstack((np.array(moneyball["OBP"]), 
               np.array(moneyball["SLG"]))).T

#New function of linear regression
rs_model = LinearRegression()

#Fitting of the function
rs_model.fit(X, y)

print("R-squared[RS_2]: %.4f" % (rs_model.score(X, y)))
#R-squared[RS_2]: 0.9296

print(rs_model.intercept_, rs_model.coef_)
# Intercept: -804.627061062 [ OBP: 2737.76802227  SLG: 1584.90860546]

#In that case, we'll put new variables to get a better and clean data. The new independent variables are  OOBP (Opponent On Base Percentage) and OSLG (Opponent Slugging Percentage)
moneyball_ra = pd.DataFrame({"OOBP": moneyball["OOBP"],
                             "OSLG": moneyball["OSLG"],
                             "RA": moneyball["RA"]})

#Remove missing values 
moneyball_ra = moneyball_ra.dropna(axis=0)

#Array with Run Allowed 
y = np.array(moneyball_ra["RA"])

#Stack arrays in row wise
X = np.vstack((np.array(moneyball_ra["OOBP"]), 
               np.array(moneyball_ra["OSLG"]))).T

#Linear regression function
ra_model = LinearRegression()

#Fitting
ra_model.fit(X, y)

#Coefficient of determination
print("R-squared[RA]: %.4f" % (ra_model.score(X, y)))
#R-squared[RA]: 0.9073

print(rs_model.intercept_, ra_model.coef_)
#Intercept: -804.627061062 [ OOBP: 2913.59948582  OSLG: 1514.28595842]

#Using the matrix opf numpy, we'll predict thr RA., RS and number of victories
pred_rs = rs_model.predict(np.matrix([0.339, 0.430]))
pred_ra = ra_model.predict(np.matrix([0.307, 0.373]))
pred_rd = pred_rs - pred_ra
pred_wins = win_model.predict(np.matrix([pred_rd]))


print("Predicted Runs Scored in 2002: %.2f" % (pred_rs))
#Predicted Runs Scored in 2002: 804.99

print("Predicted Runs Allowed in 2002: %.2f" % (pred_ra))
#Predicted Runs Allowed in 2002: 621.93

print("Predicted Wins in 2002: %.2f" % (pred_wins))
#Predicted Wins in 2002: 100.24


